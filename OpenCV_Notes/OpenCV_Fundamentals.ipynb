{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<h1><center>OpenCV Fundamentals </center></h1>",
   "id": "102ca986a4b94f97"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-07T20:36:56.132189Z",
     "start_time": "2025-07-07T20:36:56.124318Z"
    }
   },
   "source": "import cv2 as cv",
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### **Images:**",
   "id": "30d9cc7cf6415ec2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T18:04:56.279351Z",
     "start_time": "2025-07-07T18:04:56.269706Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Reading Images\n",
    "img = cv.imread('Photos/Cat.jpg')"
   ],
   "id": "bdb3957ab40ee1c5",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T17:54:00.952028Z",
     "start_time": "2025-07-07T17:53:59.329337Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Showing Images\n",
    "cv.imshow('Cat', img)\n",
    "cv.waitKey(0)"
   ],
   "id": "4f4278417baca1b5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### **Videos:**",
   "id": "1fee7d14e0141cfe"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T18:09:12.900215Z",
     "start_time": "2025-07-07T18:09:12.868933Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Reading Videos\n",
    "capture = cv.VideoCapture('Videos/dog.mp4')"
   ],
   "id": "bd9542e4a145bff9",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T17:53:08.393800Z",
     "start_time": "2025-07-07T17:52:56.516421Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Showing Videos\n",
    "while True:\n",
    "    isTrue, frame = capture.read() # returns the frame and a boolean value determining if it was read correctly \"isTrue\"\n",
    "    cv.imshow('Video', frame) # Displays each frame\n",
    "    \n",
    "    if cv.waitKey(20) & 0xFF == ord('d'): # to keep it from playing infinitely\n",
    "        break\n",
    "    # Basically saying if the letter d is pressed, break out of the loop.\n",
    "        \n",
    "# closes the capture and windows:\n",
    "capture.release()\n",
    "cv.destroyAllWindows()\n",
    "    \n",
    "# Basically, you loop through the video frame by frame"
   ],
   "id": "a733af99130ee9e7",
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.12.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:973: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'cv::imshow'\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31merror\u001B[0m                                     Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 4\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m      3\u001B[0m     isTrue, frame \u001B[38;5;241m=\u001B[39m capture\u001B[38;5;241m.\u001B[39mread() \u001B[38;5;66;03m# returns the frame and a boolean value determining if it was read correctly \"isTrue\"\u001B[39;00m\n\u001B[1;32m----> 4\u001B[0m     cv\u001B[38;5;241m.\u001B[39mimshow(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mVideo\u001B[39m\u001B[38;5;124m'\u001B[39m, frame) \u001B[38;5;66;03m# Displays each frame\u001B[39;00m\n\u001B[0;32m      6\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m cv\u001B[38;5;241m.\u001B[39mwaitKey(\u001B[38;5;241m20\u001B[39m) \u001B[38;5;241m&\u001B[39m \u001B[38;5;241m0xFF\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mord\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124md\u001B[39m\u001B[38;5;124m'\u001B[39m): \u001B[38;5;66;03m# to keep it from playing infinitely\u001B[39;00m\n\u001B[0;32m      7\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "\u001B[1;31merror\u001B[0m: OpenCV(4.12.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:973: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'cv::imshow'\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## **Resizing and Rescaling**",
   "id": "e4dd14853d84b3d5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T18:09:19.192699Z",
     "start_time": "2025-07-07T18:09:19.187902Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Rescale Function:\n",
    "\n",
    "# Works for Images, Videos, and Live Video\n",
    "def rescale_frame(frame, scale=0.75):\n",
    "    width = int(frame.shape[1] * scale) # rescaling width\n",
    "    height = int(frame.shape[0] * scale) # rescaling height\n",
    "    dimension = (width, height)\n",
    "    \n",
    "    return cv.resize(frame, dimension, interpolation=cv.INTER_AREA) # resizes the frame to a particular dimension"
   ],
   "id": "b4249dbd9af72308",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Resizing Video",
   "id": "1010b1327dfc2ad5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T18:03:38.429655Z",
     "start_time": "2025-07-07T18:03:24.256375Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Rescaling Video:\n",
    "\n",
    "while True:\n",
    "    isTrue, frame = capture.read()\n",
    "    \n",
    "    frame_resized = rescale_frame(frame, scale=0.2) # Applying a rescale of 20 percent to each frame\n",
    "    \n",
    "    cv.imshow('Video', frame) # Original Video\n",
    "    cv.imshow('Resized', frame_resized) # Resized Video\n",
    "    \n",
    "    if cv.waitKey(20) & 0xFF == ord('d'):\n",
    "        break\n",
    "        \n",
    "capture.release()\n",
    "cv.destroyAllWindows()\n"
   ],
   "id": "2f48c9a056d93fe0",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 6\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m      4\u001B[0m     isTrue, frame \u001B[38;5;241m=\u001B[39m capture\u001B[38;5;241m.\u001B[39mread()\n\u001B[1;32m----> 6\u001B[0m     frame_resized \u001B[38;5;241m=\u001B[39m rescale_frame(frame) \u001B[38;5;66;03m# Applying the rescale function to each frame\u001B[39;00m\n\u001B[0;32m      8\u001B[0m     cv\u001B[38;5;241m.\u001B[39mimshow(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mVideo\u001B[39m\u001B[38;5;124m'\u001B[39m, frame)\n\u001B[0;32m      9\u001B[0m     cv\u001B[38;5;241m.\u001B[39mimshow(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mResized\u001B[39m\u001B[38;5;124m'\u001B[39m, frame_resized) \u001B[38;5;66;03m# Showing Resized Video\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[8], line 4\u001B[0m, in \u001B[0;36mrescale_frame\u001B[1;34m(frame, scale)\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrescale_frame\u001B[39m(frame, scale\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.75\u001B[39m):\n\u001B[1;32m----> 4\u001B[0m     width \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(frame\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m*\u001B[39m scale) \u001B[38;5;66;03m# rescaling width\u001B[39;00m\n\u001B[0;32m      5\u001B[0m     height \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(frame\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m*\u001B[39m scale) \u001B[38;5;66;03m# rescaling height\u001B[39;00m\n\u001B[0;32m      6\u001B[0m     dimension \u001B[38;5;241m=\u001B[39m (width, height)\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Second Way of Resizing Videos *(Doesn't apply to Images)*",
   "id": "f87b9c18b15f5847"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Only Works for Live Video\n",
    "def change_res(width, height):\n",
    "    # 3 and 4 represent the properties of the capture class.\n",
    "    # 3 represents the width, 4 represents the height.\n",
    "    capture.set(3, width)\n",
    "    capture.set(4, height)"
   ],
   "id": "30cea2b1f2a58f71"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Resizing Images",
   "id": "101f6957e0e0ac9d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T18:09:21.761722Z",
     "start_time": "2025-07-07T18:09:21.721818Z"
    }
   },
   "cell_type": "code",
   "source": "img = cv.imread('Photos/cat_large.jpg')",
   "id": "279884b0cccb9ab",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T18:09:38.235539Z",
     "start_time": "2025-07-07T18:09:34.709404Z"
    }
   },
   "cell_type": "code",
   "source": [
    "resized_img = rescale_frame(img, scale=0.2) # Applying a rescale of 20 percent\n",
    "cv.imshow('Image', resized_img)\n",
    "\n",
    "cv.waitKey(0)"
   ],
   "id": "3a0038e936982902",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## **Drawing Shapes and adding Text**",
   "id": "b0f65c3ca6ca7117"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T18:15:08.140983Z",
     "start_time": "2025-07-07T18:15:08.137121Z"
    }
   },
   "cell_type": "code",
   "source": "import numpy as np",
   "id": "4abe0318190bc916",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T18:19:20.219342Z",
     "start_time": "2025-07-07T18:19:20.212961Z"
    }
   },
   "cell_type": "code",
   "source": [
    "blank = np.zeros((500,500,3), dtype='uint8') # Creating a 500 by 500 array and giving it the data type of image.\n",
    "# This creates a blank image to work on."
   ],
   "id": "d7fc68444b598e18",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T18:19:26.803736Z",
     "start_time": "2025-07-07T18:19:22.965583Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Coloring blank image green:\n",
    "blank[:] = 0,255,0 # selecting all elements, changing to green\n",
    "cv.imshow('Green', blank)\n",
    "cv.waitKey(0)"
   ],
   "id": "a7317a16a99696d1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T18:20:14.581490Z",
     "start_time": "2025-07-07T18:20:13.150904Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Coloring blank image red:\n",
    "blank[:] = 0,0,255\n",
    "cv.imshow('Green', blank)\n",
    "cv.waitKey(0)"
   ],
   "id": "81e454f47cfcea33",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T18:34:12.917303Z",
     "start_time": "2025-07-07T18:34:11.185842Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Coloring part of the image:\n",
    "blank[200:300, 300:400] = 0,0,255\n",
    "cv.imshow('Green', blank)\n",
    "cv.waitKey(0)"
   ],
   "id": "2ae8604eaa1e6dfc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T18:34:15.557422Z",
     "start_time": "2025-07-07T18:34:14.314913Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Drawing a rectangle\n",
    "blank = np.zeros((500,500,3), dtype='uint8') # resetting blank\n",
    "\n",
    "# cv.rectangle(image, pt1, pt2, color, thickness=None, lineType=None, shift=None)\n",
    "# - Do thickness=cv.FILLED (or -1), to create a filled rectangle\n",
    "\n",
    "cv.rectangle(blank, (0,0), (250,250), (0,255,0), thickness=2) # so coloring blank image from 0,0 (origin) to point of 250,250 with color of green and thickness of 2\n",
    "\n",
    "cv.imshow('Rectangle', blank)\n",
    "cv.waitKey(0)"
   ],
   "id": "9d48535086ceaae3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T18:37:28.732981Z",
     "start_time": "2025-07-07T18:37:27.071885Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Drawing a circle:\n",
    "blank = np.zeros((500,500,3), dtype='uint8')\n",
    "\n",
    "# cv.circle(img, center, radius:int, color, ...)\n",
    "\n",
    "cv.circle(blank, (250,250), 40, (0,0,255), thickness=3)\n",
    "cv.imshow('Circle', blank)\n",
    "cv.waitKey(0)"
   ],
   "id": "2f3b1e1be930414e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T18:40:03.151027Z",
     "start_time": "2025-07-07T18:40:01.399006Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Drawing a line:\n",
    "blank = np.zeros((500,500,3), dtype='uint8')\n",
    "\n",
    "# cv.line(img, pt1, pt2, color, ...)\n",
    "\n",
    "cv.line(blank, (100,0), (200,250), (255,255,0), thickness=2)\n",
    "cv.imshow(\"Line\", blank)\n",
    "cv.waitKey(0)"
   ],
   "id": "ebf0d433df0f3d12",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T18:41:08.761921Z",
     "start_time": "2025-07-07T18:41:06.529452Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Writing Text on an image:\n",
    "blank = np.zeros((500,500,3), dtype='uint8')\n",
    "\n",
    "cv.putText(blank, 'Hello', (255,255), cv.FONT_HERSHEY_PLAIN, 2.0, (0,0,255))\n",
    "\n",
    "cv.imshow(\"Text\", blank)\n",
    "cv.waitKey(0)"
   ],
   "id": "ad6cee36465a8170",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## **Essential Functions**",
   "id": "6d582ad3cbc4a97e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T18:47:21.838639Z",
     "start_time": "2025-07-07T18:47:21.826703Z"
    }
   },
   "cell_type": "code",
   "source": "img = cv.imread('Photos/cat.jpg')",
   "id": "399275ff4e96f539",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Converting an Image to Grayscale:",
   "id": "f09acc3525bf0ae5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T18:44:05.112721Z",
     "start_time": "2025-07-07T18:43:59.710665Z"
    }
   },
   "cell_type": "code",
   "source": [
    "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "cv.imshow('Gray', gray)\n",
    "cv.waitKey(0)"
   ],
   "id": "9bebead0901afc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Applying Blur to Images",
   "id": "40cd1216ef8a4fde"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T18:48:34.364672Z",
     "start_time": "2025-07-07T18:48:32.963021Z"
    }
   },
   "cell_type": "code",
   "source": [
    "blur = cv.GaussianBlur(img, (7,7), cv.BORDER_DEFAULT)\n",
    "# Increasing the kernel size (the middle argument) increases the blur. The kernel size must be two odd numbers.\n",
    "\n",
    "cv.imshow('Gaussian', blur)\n",
    "cv.waitKey(0)"
   ],
   "id": "2e5cbab1154a4c1e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Edge Cascade  \n",
    "Basically trying to find the edges that are present in the image."
   ],
   "id": "7601bd87b95b6722"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T18:50:32.085182Z",
     "start_time": "2025-07-07T18:50:30.393104Z"
    }
   },
   "cell_type": "code",
   "source": [
    "canny = cv.Canny(img, 125, 175)\n",
    "# Apply a blurred image to get less edges.\n",
    "\n",
    "cv.imshow('Canny', canny)\n",
    "cv.waitKey(0)"
   ],
   "id": "f4e34a2ab3329b9e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Dilating the Image (Edges)",
   "id": "be44c84b369eae11"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T18:51:45.106780Z",
     "start_time": "2025-07-07T18:51:39.163746Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dilated = cv.dilate(canny, (7,7), iterations=3)\n",
    "\n",
    "cv.imshow('Dilated', dilated)\n",
    "cv.waitKey(0)"
   ],
   "id": "2422c87925f39d2f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Eroding (Edges)",
   "id": "3442f1adf157e626"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T18:52:58.580873Z",
     "start_time": "2025-07-07T18:52:33.360316Z"
    }
   },
   "cell_type": "code",
   "source": [
    "eroded = cv.erode(dilated, (3,3), iterations=1)\n",
    "\n",
    "cv.imshow('Eroded', eroded)\n",
    "cv.waitKey(0)"
   ],
   "id": "8ac4cbc1bb641d04",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Resizing",
   "id": "1fe156c2b780e60"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T18:54:25.429768Z",
     "start_time": "2025-07-07T18:54:24.031403Z"
    }
   },
   "cell_type": "code",
   "source": [
    "resized = cv.resize(img, (500,500), interpolation=cv.INTER_AREA)\n",
    "\n",
    "# interpolation - determines how pixel values are calculated when resizing an image\n",
    "# Different Types:\n",
    "# - cv.INTER_LINEAR : best for enlarging images\n",
    "# - cv.INTER_CUBIC : enlarging images, slower but better quality\n",
    "# - cv.INTER_AREA : best for shrinking images\n",
    "# and more...\n",
    "\n",
    "cv.imshow('Resized', resized)\n",
    "cv.waitKey(0)"
   ],
   "id": "51bcc71445f6f2b4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Cropping  \n",
    "Cropping, among other things in OpenCV, is just manipulating the array of an image as images are really just numpy arrays."
   ],
   "id": "729e59d62e912c2f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T19:02:38.550579Z",
     "start_time": "2025-07-07T19:02:35.844424Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cropped = img[50:200, 200:400]\n",
    "\n",
    "cv.imshow('Cropped', cropped)\n",
    "cv.waitKey(0)"
   ],
   "id": "3432ce96d1570205",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## **Basic Images Transformations**",
   "id": "42b026647f449f94"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Translation  \n",
    "Shifting an image along the x and y axis."
   ],
   "id": "1c9862861d3734bc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T20:38:45.193836Z",
     "start_time": "2025-07-07T20:38:43.673947Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def translate(img, x, y):\n",
    "    trans_mat = np.float32([[1, 0, x], [0, 1, y]])\n",
    "    dimensions = (img.shape[1], img.shape[0])\n",
    "    return cv.warpAffine(img, trans_mat, dimensions)\n",
    "\n",
    "# -x --> Left\n",
    "# -y --> Up\n",
    "# +x --> Right\n",
    "# +y --> Down\n",
    "\n",
    "translated = translate(img, 100, 100)\n",
    "\n",
    "cv.imshow('Translated', translated)\n",
    "cv.waitKey(0)"
   ],
   "id": "486bf4d3ddd18035",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Rotation",
   "id": "815e553a0f6af8db"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T20:41:23.674959Z",
     "start_time": "2025-07-07T20:41:18.874067Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def rotate(img, angle, rot_point=None):\n",
    "    (height, width) = img.shape[:2]\n",
    "    \n",
    "    if rot_point is None: # If rotation point is none, it will rotate around the center\n",
    "        rot_point = (width // 2, height // 2)\n",
    "        \n",
    "    rot_mat = cv.getRotationMatrix2D(rot_point, angle, 1.0)\n",
    "    dimensions = (width, height)\n",
    "    \n",
    "    return cv.warpAffine(img, rot_mat, dimensions)\n",
    "\n",
    "rotated = rotate(img, 45)\n",
    "cv.imshow('Rotated', rotated)\n",
    "cv.waitKey(0)"
   ],
   "id": "530debf2ccc9ecb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Flipping an Image",
   "id": "1277877ffad72f26"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T20:47:43.422568Z",
     "start_time": "2025-07-07T20:47:41.238960Z"
    }
   },
   "cell_type": "code",
   "source": [
    "flip = cv.flip(img, 0)\n",
    "#flip = cv.flip(image, flip_code:int)\n",
    "# Takes in a flip code: \n",
    "# * 0 means vertical (over x-axis)\n",
    "# * 1 means horizontally (over y-axis)\n",
    "# * -1 means both vertically & horizontally\n",
    "\n",
    "cv.imshow('Flipped', flip)\n",
    "cv.waitKey(0)"
   ],
   "id": "57bfc412ac3b5eb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 61
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## **Contour Detection**  \n",
    "Contours are the boundaries of objects."
   ],
   "id": "158b03e8f8100c87"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T21:25:03.929253Z",
     "start_time": "2025-07-07T21:25:03.604650Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2 as cv\n",
    "img = cv.imread('Photos/cats.jpg')"
   ],
   "id": "6189928b2d99f158",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T21:25:06.136976Z",
     "start_time": "2025-07-07T21:25:03.965342Z"
    }
   },
   "cell_type": "code",
   "source": [
    "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY) # Converting to Grayscale\n",
    "cv.imshow('Gray', gray)\n",
    "cv.waitKey(0)"
   ],
   "id": "1e6b08d8957a726e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T21:25:08.973367Z",
     "start_time": "2025-07-07T21:25:07.466237Z"
    }
   },
   "cell_type": "code",
   "source": [
    "blur = cv.GaussianBlur(gray, (5,5), cv.BORDER_DEFAULT) # Applying Blur\n",
    "cv.imshow('Gaussian', blur)\n",
    "cv.waitKey(0)"
   ],
   "id": "acc31ec540d83cd2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T21:25:11.824480Z",
     "start_time": "2025-07-07T21:25:10.162223Z"
    }
   },
   "cell_type": "code",
   "source": [
    "canny = cv.Canny(blur, 125, 175) # Apply Edge Cascade\n",
    "cv.imshow('Canny', canny)\n",
    "cv.waitKey(0)"
   ],
   "id": "9f067addea88f5ce",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Finding the Contours:",
   "id": "e9631db5633307a1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T21:25:14.707629Z",
     "start_time": "2025-07-07T21:25:14.689705Z"
    }
   },
   "cell_type": "code",
   "source": [
    "contours, hierarchies = cv.findContours(canny, cv.RETR_LIST, cv.CHAIN_APPROX_SIMPLE)\n",
    "print(f'{len(contours)} contours found')"
   ],
   "id": "fd9e7448a502805d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "380 contours found\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    " This method looks at the edges found in the image and returns two values:\n",
    " * contours - a python list of all the contours found\n",
    " * hierarchies - info about the relationship between contours\n",
    "\n",
    "#### cv.findContours(image, mode, method)\n",
    "### Parameter breakdown:\n",
    " * image - image being analyzed for contours\n",
    " * mode - how contours are retrieved  \n",
    "       - cv.RETR_LIST: Retrieves all contours with no hierarchy (ignores parent/child relationships).  \n",
    "   *Alternatives:*  \n",
    "       - cv.RETR_TREE: Full hierarchy (parent-child relationships)  \n",
    "       - cv.RETR_EXTERNAL: Only outermost contours\n",
    " * method - how contour points are stored  \n",
    "       - cv.CHAIN_APPROX_NONE: Stores every single point along the contour (very detailed)  \n",
    "   *Alternative:*  \n",
    "       - cv.CHAIN_APPROX_SIMPLE: Compresses the contour by removing redundant points (faster, usually preferred)"
   ],
   "id": "bdb389f09b6994d3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Another way of finding contours:",
   "id": "f98fd71145424875"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T21:25:18.885609Z",
     "start_time": "2025-07-07T21:25:17.530461Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ret, thresh = cv.threshold(gray, 125, 255, cv.THRESH_BINARY)\n",
    "\n",
    "cv.imshow('Thresh', thresh)\n",
    "cv.waitKey(0)\n",
    "\n",
    "# thresholding - looks at an image and tries to binarize it"
   ],
   "id": "e0cb3297bf3d88f4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T21:25:21.327227Z",
     "start_time": "2025-07-07T21:25:21.308085Z"
    }
   },
   "cell_type": "code",
   "source": [
    "contours, hierarchies = cv.findContours(thresh, cv.RETR_LIST, cv.CHAIN_APPROX_SIMPLE)\n",
    "print(f'{len(contours)} contours found')"
   ],
   "id": "e89c035f4cd5181c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "839 contours found\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Drawing Contours on a Blank Image",
   "id": "19747dad3f14b07b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T21:29:38.503855Z",
     "start_time": "2025-07-07T21:29:38.491776Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "# Creating a blank image the same save as the cats image:\n",
    "blank = np.zeros(img.shape, dtype='uint8')"
   ],
   "id": "7e307ac643b662f",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T21:29:52.620033Z",
     "start_time": "2025-07-07T21:29:39.091821Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cv.drawContours(blank, contours, -1, (0,0,255), 1)\n",
    "\n",
    "cv.imshow('Contours Drawn', blank)\n",
    "cv.waitKey(0)"
   ],
   "id": "7ee67d78d9d6687f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### cv.drawContours(image, contours, contourIdx, color, thickness)  \n",
    "#### **Parameter Breakdown**  \n",
    "* image - image to draw on\n",
    "* contours - the list of contours you got from cv.findContours()\n",
    "* contourIdx - index of the contour to draw (-1 = draw all contours\n",
    "* color - the color of the contours\n",
    "* thickness - the thickness of the contour lines"
   ],
   "id": "bceae52580b87267"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
